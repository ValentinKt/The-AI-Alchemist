{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "from keras.saving import register_keras_serializable\n",
    "\n",
    "# Set environment variables\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '0'  # Enable all logs\n",
    "\n",
    "# Optimize CPU usage\n",
    "tf.config.threading.set_intra_op_parallelism_threads(8)\n",
    "tf.config.threading.set_inter_op_parallelism_threads(8)\n",
    "\n",
    "# Enable mixed precision\n",
    "from tensorflow.keras import mixed_precision\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)\n",
    "\n",
    "# Vérifiez si le GPU Metal est disponible\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "# Activez la croissance de mémoire dynamique pour le GPU\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Compute devices:\", tf.config.list_physical_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess Fashion MNIST data\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "def preprocess_data(images, labels):\n",
    "    images = tf.cast(images, tf.float32) / 255.0\n",
    "    images = tf.expand_dims(images, -1)\n",
    "    return images, labels\n",
    "\n",
    "def augment(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_brightness(image, max_delta=0.1)\n",
    "    image = tf.image.random_contrast(image, lower=0.9, upper=1.1)\n",
    "    return image, label\n",
    "\n",
    "# Create efficient data pipelines\n",
    "BATCH_SIZE = 512\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "train_ds = train_ds.map(preprocess_data, num_parallel_calls=AUTOTUNE)\n",
    "train_ds = train_ds.cache().shuffle(60000).batch(BATCH_SIZE)\n",
    "train_ds = train_ds.map(augment, num_parallel_calls=AUTOTUNE)\n",
    "train_ds = train_ds.prefetch(AUTOTUNE)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
    "test_ds = test_ds.map(preprocess_data, num_parallel_calls=AUTOTUNE)\n",
    "test_ds = test_ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a more complex model using Functional API\n",
    "def create_model():\n",
    "    inputs = tf.keras.Input(shape=(28, 28, 1))\n",
    "    x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.l2(0.01))(inputs)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    x = tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    outputs = tf.keras.layers.Dense(10)(x)\n",
    "    return tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "@register_keras_serializable()\n",
    "class AdjustableLearningRateSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, initial_learning_rate, decay_steps, decay_rate):\n",
    "        self.initial_learning_rate = tf.cast(initial_learning_rate, tf.float32)\n",
    "        self.decay_steps = tf.cast(decay_steps, tf.float32)\n",
    "        self.decay_rate = tf.cast(decay_rate, tf.float32)\n",
    "        self.current_learning_rate = tf.Variable(self.initial_learning_rate, dtype=tf.float32)\n",
    "\n",
    "    def __call__(self, step):\n",
    "        step = tf.cast(step, tf.float32)\n",
    "        return self.current_learning_rate * tf.math.pow(self.decay_rate, step / self.decay_steps)\n",
    "\n",
    "    def adjust_learning_rate(self, factor):\n",
    "        self.current_learning_rate.assign(self.current_learning_rate * tf.cast(factor, tf.float32))\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\n",
    "            \"initial_learning_rate\": float(self.initial_learning_rate.numpy()),\n",
    "            \"decay_steps\": float(self.decay_steps.numpy()),\n",
    "            \"decay_rate\": float(self.decay_rate.numpy()),\n",
    "        }\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n",
    "\n",
    "# Créez le modèle\n",
    "model = create_model()\n",
    "\n",
    "# Définissez le learning rate schedule\n",
    "initial_learning_rate = 0.001\n",
    "lr_schedule = AdjustableLearningRateSchedule(\n",
    "    initial_learning_rate=initial_learning_rate,\n",
    "    decay_steps=100000.0,\n",
    "    decay_rate=0.96\n",
    ")\n",
    "\n",
    "# Créez l'optimiseur\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "# Compilez le modèle\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom callback to adjust learning rate\n",
    "class AdjustLearningRateCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, schedule, monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6):\n",
    "        super(AdjustLearningRateCallback, self).__init__()\n",
    "        self.schedule = schedule\n",
    "        self.monitor = monitor\n",
    "        self.factor = tf.cast(factor, tf.float32)\n",
    "        self.patience = patience\n",
    "        self.min_lr = tf.cast(min_lr, tf.float32)\n",
    "        self.wait = 0\n",
    "        self.best = float('inf')\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current = logs.get(self.monitor)\n",
    "        if current < self.best:\n",
    "            self.best = current\n",
    "            self.wait = 0\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.patience:\n",
    "                new_lr = tf.maximum(self.schedule.current_learning_rate * self.factor, self.min_lr)\n",
    "                self.schedule.current_learning_rate.assign(new_lr)\n",
    "                print(f'\\nEpoch {epoch+1}: reducing learning rate to {new_lr.numpy():.6f}')\n",
    "                self.wait = 0\n",
    "\n",
    "# Callbacks\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True, mode='max'),\n",
    "    tf.keras.callbacks.ModelCheckpoint('best_model.weights.h5', monitor='val_accuracy', save_best_only=True, save_weights_only=True, mode='max'),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1),\n",
    "    AdjustLearningRateCallback(lr_schedule)\n",
    "]\n",
    "\n",
    "# Train the model\n",
    "EPOCHS = 100\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=test_ds,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accédez à l'historique d'entraînement\n",
    "train_loss = history.history['loss']\n",
    "train_accuracy = history.history['accuracy']\n",
    "val_loss = history.history['val_loss']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "# Load the best model weights\n",
    "model.load_weights('best_model.weights.h5')\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_ds, verbose=2)\n",
    "print(f'\\nTest accuracy: {test_acc:.4f}')\n",
    "\n",
    "# Plot and save training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_accuracy, label='Training Accuracy')\n",
    "plt.plot(val_accuracy, label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png')\n",
    "plt.show()\n",
    "\n",
    "print(\"Training history plot saved as 'training_history.png'\")\n",
    "print(f\"Training stopped at epoch: {len(train_accuracy)}\")\n",
    "print(f\"Best validation accuracy: {max(val_accuracy):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test-time augmentation\n",
    "@tf.function\n",
    "def tta_predict(model, image, num_augmentations=10):\n",
    "    predictions = tf.TensorArray(tf.float32, size=num_augmentations)\n",
    "    for i in tf.range(num_augmentations):\n",
    "        augmented_image, _ = augment(image, None)\n",
    "        pred = model(augmented_image, training=False)\n",
    "        pred = tf.cast(pred, tf.float32)  # Cast to float32\n",
    "        predictions = predictions.write(i, pred)\n",
    "    return tf.reduce_mean(predictions.stack(), axis=0)\n",
    "\n",
    "# Apply test-time augmentation to a few test samples\n",
    "num_samples = 5\n",
    "tta_results = []\n",
    "for i in range(num_samples):\n",
    "    sample = test_ds.take(1).get_single_element()[0][i:i+1]\n",
    "    tta_pred = tta_predict(model, sample)\n",
    "    tta_results.append(tf.argmax(tta_pred, axis=-1).numpy()[0])\n",
    "\n",
    "print(\"Test-Time Augmentation predictions for first 5 samples:\", tta_results)\n",
    "print(\"Actual labels for first 5 samples:\", test_labels[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get class names\n",
    "def get_class_names():\n",
    "    return ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "            'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "class_names = get_class_names()\n",
    "\n",
    "# Function to plot images with predictions\n",
    "def plot_image(i, predictions_array, true_label, img):\n",
    "    true_label, img = true_label[i], img[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.imshow(img.reshape((28,28)), cmap=plt.cm.binary)\n",
    "\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    if predicted_label == true_label:\n",
    "        color = 'blue'\n",
    "    else:\n",
    "        color = 'red'\n",
    "\n",
    "    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "                                100*np.max(predictions_array),\n",
    "                                class_names[true_label]),\n",
    "                                color=color)\n",
    "\n",
    "# Function to plot value array\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "    true_label = true_label[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks(range(10))\n",
    "    plt.yticks([])\n",
    "    thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
    "    plt.ylim([0, 1])\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "\n",
    "    thisplot[predicted_label].set_color('red')\n",
    "    thisplot[true_label].set_color('blue')\n",
    "\n",
    "# Plot a grid of predictions\n",
    "num_rows = 5\n",
    "num_cols = 3\n",
    "num_images = num_rows*num_cols\n",
    "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
    "for i in range(num_images):\n",
    "    plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "    plot_image(i, model.predict(test_ds.take(1).get_single_element()[0][i:i+1])[0], test_labels, test_images)\n",
    "    plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "    plot_value_array(i, model.predict(test_ds.take(1).get_single_element()[0][i:i+1])[0], test_labels)\n",
    "plt.tight_layout()\n",
    "plt.savefig('prediction_grid.png')\n",
    "plt.show()\n",
    "\n",
    "print(\"Prediction grid saved as 'prediction_grid.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "predictions = model.predict(test_ds)\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "cm = confusion_matrix(test_labels, y_pred)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig('confusion_matrix.png')\n",
    "plt.show()\n",
    "\n",
    "print(\"Confusion matrix saved as 'confusion_matrix.png'\")\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(test_labels, y_pred, target_names=class_names))\n",
    "\n",
    "# Save the model summary\n",
    "with open('model_summary.txt', 'w') as f:\n",
    "    model.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
    "\n",
    "print(\"Model summary saved as 'model_summary.txt'\")\n",
    "\n",
    "print(\"\\nTraining and evaluation complete!\")\n",
    "\n",
    "# Clear the session to free up resources\n",
    "tf.keras.backend.clear_session()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
